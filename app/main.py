from fastapi import FastAPI, WebSocket
import cv2
import numpy as np
import base64
import asyncio
import time
import os

from app.rabbitmq import *

app = FastAPI()

# ‡πÇ‡∏´‡∏•‡∏î Haar Cascade ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ RabbitMQ ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤
connection, channel = get_rabbitmq_connection()

output_folder = "faces"
os.makedirs(output_folder, exist_ok=True)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ

camera_id = "CAM_01"

def compress_and_encode_image(image, quality=100):
    """ ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏õ‡πá‡∏ô bytes """
    if not isinstance(image, np.ndarray):
        raise TypeError("Input image ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array")

    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
    
    # ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô
    print(f"üìå Shape of image: {image.shape} | Dtype: {image.dtype}")

    success, encoded_image = cv2.imencode(".jpg", image, encode_param)
    
    if success:
        print(f"‚úÖ Encoded image size: {len(encoded_image)} bytes")
        return encoded_image.tobytes()
    else:
        raise ValueError("‚ùå Failed to encode image")


@app.websocket("/video_feed")
async def video_feed(websocket: WebSocket):

    await websocket.accept()

    # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡πÉ‡∏ä‡πâ index 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å)
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("‚ùå Camera not found! Trying to reconnect...")
        time.sleep(2)
        cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏ó‡∏µ‡πà frontend ‡∏ñ‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°
        await websocket.send_text("Unable to connect camera, please check the camera.")
        cap.release()
        return

    image_count = 0  # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    last_detection_time = 0
    #time delay for crop images
    detection_delay = 2 

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                await websocket.send_text("The camera is not turned on.")
                break

            # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô Grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)
            if len(faces) > 0:
                current_time = time.time()  # ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏ô‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if current_time - last_detection_time >= detection_delay:
                    # ‡πÄ‡∏£‡∏¥‡πà‡∏° crop ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                    last_detection_time = current_time  # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
                    
                    padding = 100

                    # Crop ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                    for (x, y, w, h) in faces:
                        # ‡∏´‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏π‡∏á)
                        max_size = max(w, h)

                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏°‡∏≤‡∏ï‡∏£
                        x1 = max(x + w//2 - max_size//2 - padding, 0)  
                        x2 = min(x + w//2 + max_size//2 + padding, frame.shape[1])  
                        y1 = max(y + h//2 - max_size//2 - padding, 0)  
                        y2 = min(y + h//2 + max_size//2 + padding, frame.shape[0])  

                        # Crop ‡∏†‡∏≤‡∏û‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Ç‡∏¢‡∏≤‡∏¢
                        face_crop = frame[y1:y2, x1:x2]

                        # ‡∏£‡∏µ‡πÑ‡∏ã‡∏™‡πå‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡πÄ‡∏ä‡πà‡∏ô 160x160)
                        face_crop_resized = cv2.resize(face_crop, (160, 160))

                        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
                        image_count += 1
                        filename = os.path.join(output_folder, f"face_{image_count}.jpg")
                        cv2.imwrite(filename, face_crop_resized)
                        print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {image_count}: {filename}")

                        image_bytes = compress_and_encode_image(face_crop, quality=100)
                        send_image_to_rabbitmq(channel, image_bytes, camera_id)

            else:
                # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                last_detection_time = 0  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤

            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô base64 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô WebSocket
            _, buffer = cv2.imencode(".jpg", frame)
            frame_base64 = base64.b64encode(buffer).decode("utf-8")

            # ‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û‡πÑ‡∏õ‡∏¢‡∏±‡∏á Client
            await websocket.send_text(frame_base64)

    except Exception as e:
        print(f"Error: {e}")
    
    finally:
        cap.release()
        await websocket.close()